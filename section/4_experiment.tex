本節では本研究で実施した予備実験および本実験の設計と結果を示す。

\section*{予備実験1：日本語BERTモデルによる単語間類似度測定}
自然言語処理モデルの代表的なものとして、BERTがある。その中でも日本語に特化したCl-tohokuモデルを利用し、単語間のコサイン類似度を計測した。しかし、「介護」と「極悪非道」の類似度が0.678であったり、「看護師」と「ナース」よりも「介護士」と「ナース」のほうが数値的に近かったりと、直感的に数値があまり合わなかった。この結果から、単一モデルに依存せず、横断的に複数モデルの検討を行うことの重要性が示された。

\section*{予備実験2：BERTモデルの横断評価}
複数のBERT系モデル（日本語Sentence-BERT、マルチリンガルSentence-BERT、BERT-largeなど）を比較し、職種間の分離度を評価した。分離度は類似職種グループと非類似職種グループの平均スコア差で定義する。

\begin{table}[htbp]
\centering
\caption{BERTモデル別の分離度スコア}
\begin{tabular}{l r}
\hline
モデル & 分離度スコア \\
\hline
Sentence-BERT (Japanese) & 0.398 \\
Sentence-BERT (Multilingual) & 0.349 \\
BERT-large (Mean Pooling) & 0.111 \\
BERT-large (CLS) & 0.063 \\
BERT (Mean Pooling) & 0.039 \\
BERT (CLS) & 0.019 \\
\hline
\end{tabular}
\end{table}

\section*{本実験1：過去の応募履歴からの推定}
学習データとして過去30件、テストデータ10件を用い、過去応募の平均ベクトルから次に選択される求人を推測した。評価指標としてTop-1/Top-3/Top-5精度および複合スコアを算出した。

\begin{table}[htbp]
\centering
\caption{本実験1：ワーカー別の推薦精度}
\small
\begin{tabular}{c l r r r r}
\hline
順位 & ワーカー & Top-1 & Top-3 & Top-5 & 複合スコア \\
\hline
1 & ワーカーA & 100.0\% & 100.0\% & 100.0\% & 1.0000 \\
2 & ワーカーB & 100.0\% & 100.0\% & 100.0\% & 1.0000 \\
3 & ワーカーC & 60.0\% & 80.0\% & 80.0\% & 0.7000 \\
4 & ワーカーD & 60.0\% & 60.0\% & 60.0\% & 0.6000 \\
5 & ワーカーE & 20.0\% & 80.0\% & 80.0\% & 0.5000 \\
6 & ワーカーF & 10.0\% & 80.0\% & 80.0\% & 0.4500 \\
7 & ワーカーG & 20.0\% & 30.0\% & 40.0\% & 0.2700 \\
8 & ワーカーH & 10.0\% & 30.0\% & 60.0\% & 0.2600 \\
9 & ワーカーI & 0.0\% & 30.0\% & 40.0\% & 0.1700 \\
10 & ワーカーJ & 10.0\% & 10.0\% & 30.0\% & 0.1400 \\
\hline
\multicolumn{2}{c}{全体平均（10名）} & \textbf{39.0\%} & \textbf{60.0\%} & \textbf{67.0\%} & \textbf{0.5090} \\
\hline
\end{tabular}
\end{table}

多く働いているユーザー（ワーカーA、B）は100\%の精度で予測できるが、利用頻度が低いユーザー（ワーカーI、J）は精度が大幅に低下する傾向が見られた。

\section*{本実験2：複数項目の重み付けによる精度向上}
求人タイトル、業務内容、介護項目、施設、勤務時間、時給、勤務日など7項目を抽出し、各項目に重みを付与して評価した。以下に一部結果を示す。

\begin{table}[htbp]
\centering
\caption{本実験2（20件学習）の全パターン}
\scriptsize
\begin{tabular}{c l r r r r}
\hline
順位 & \multicolumn{1}{c}{パターン名} & Top-1 & Top-3 & Top-5 & 複合スコア \\
\hline
1 & 均等 & 57.1\% & 70.6\% & 77.1\% & 0.7112 \\
2 & 介護・施設重視 & 58.2\% & 68.2\% & 77.6\% & 0.7094 \\
3 & 勤務時間重視 & 52.9\% & 68.2\% & 77.1\% & 0.6959 \\
4 & 時給×勤務時間強化 & 54.1\% & 69.4\% & 75.9\% & 0.6959 \\
5 & 時給重視 & 51.8\% & 69.4\% & 76.5\% & 0.6941 \\
6 & 勤務条件重視 & 55.3\% & 67.7\% & 75.9\% & 0.6929 \\
7 & 極度時給重視 & 52.9\% & 65.3\% & 74.7\% & 0.6753 \\
8 & 高バランス型 & 49.4\% & 65.3\% & 74.1\% & 0.6653 \\
9 & 業務内容×時給 & 51.8\% & 62.9\% & 74.1\% & 0.6629 \\
10 & 求人タイトル重視 & 55.3\% & 67.1\% & 70.0\% & 0.6618 \\
\hline
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{本実験2（30件学習）の全パターン}
\scriptsize
\begin{tabular}{c l r r r r}
\hline
順位 & \multicolumn{1}{c}{パターン名} & Top-1 & Top-3 & Top-5 & 複合スコア \\
\hline
1 & 総合重視 & 30.0\% & 56.0\% & 63.0\% & 0.5430 \\
2 & 時給×勤務時間強化 & 38.0\% & 49.0\% & 63.0\% & 0.5380 \\
3 & 業務×介護×時給 & 32.0\% & 52.0\% & 61.0\% & 0.5250 \\
4 & 求人タイトル重視 & 38.0\% & 51.0\% & 59.0\% & 0.5240 \\
5 & 実務重視 & 26.0\% & 55.0\% & 60.0\% & 0.5170 \\
6 & 業務内容×時給 & 37.0\% & 50.0\% & 57.0\% & 0.5090 \\
7 & 高バランス型 & 33.0\% & 54.0\% & 56.0\% & 0.5080 \\
8 & 介護・施設重視 & 37.0\% & 47.0\% & 57.0\% & 0.5000 \\
9 & 超業務内容重視 & 35.0\% & 48.0\% & 57.0\% & 0.4990 \\
10 & 均等 & 34.0\% & 50.0\% & 56.0\% & 0.4980 \\
\hline
\end{tabular}
\end{table}

学習データ数を変化させた場合の精度推移では、学習データが15件〜20件の時点で最高値を示し、それを超えると精度が悪化する傾向が観察された。

\begin{table}[htbp]
\centering
\caption{学習データ数による精度推移（Top-5精度）}
\scriptsize
\begin{tabular}{l r r r r r r}
\hline
パターン & 5件 & 10件 & 15件 & 20件 & 25件 & 30件 \\
\hline
均等 (equal) & 0.69 & 0.62 & 0.74 & \textbf{0.77} & 0.62 & 0.56 \\
介護・施設重視 & 0.64 & 0.64 & \textbf{0.77} & 0.77 & 0.61 & 0.57 \\
時給×勤務時間強化 & 0.68 & 0.64 & 0.72 & \textbf{0.76} & 0.62 & 0.63 \\
高バランス型 & 0.70 & 0.62 & 0.72 & \textbf{0.74} & 0.60 & 0.56 \\
求人タイトル重視 & 0.68 & 0.67 & 0.72 & \textbf{0.70} & 0.59 & 0.59 \\
\hline
\end{tabular}
\end{table}

上記の表から、20件を超えると全てのパターンで精度が低下することが明確に示された。これは過去の嗜好データが現在の嗜好と乖離するためと考えられる。

\section*{実験3：TF-IDFとBERTの比較}
単語出現頻度に基づくTF-IDF、ルールベース（単語一致）、およびBERTによる意味的類似度を比較した結果、短文やタイトルレベルの比較ではTF-IDFが実用上十分な精度を出す場合があり、計算コストの点で有利であることがわかった。

\begin{table}[htbp]
\centering
\caption{実験3の結果（概略）}
\begin{tabular}{l c l}
\hline
手法 & 精度 & 特徴 \\
\hline
ルールベース（単語一致） & 0.8 & シンプルだが限界あり \\
BERT（意味的類似度） & 1.0 & 最高精度だが計算コスト高 \\
TF-IDF（頻度ベース） & 1.0 & 計算コスト低で有効な場合あり \\
\hline
\end{tabular}
\end{table}
